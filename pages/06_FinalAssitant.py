
# (EN)
# Refactor the agent you made in the previous assignment into an OpenAI Assistant.
# Give it a user interface with Streamlit that displays the conversation history.
# Allow the user to use its own OpenAI API Key, load it from an st.input inside of st.sidebar
# Using st.sidebar put a link to the Github repo with the code of your Streamlit app.

# (KR)
# ì´ì „ ê³¼ì œì—ì„œ ë§Œë“  ì—ì´ì „íŠ¸ë¥¼ OpenAI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œ ë¦¬íŒ©í„°ë§í•©ë‹ˆë‹¤.
# ëŒ€í™” ê¸°ë¡ì„ í‘œì‹œí•˜ëŠ” Streamlit ì„ ì‚¬ìš©í•˜ì—¬ ìœ ì € ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•˜ì„¸ìš”.
# ìœ ì €ê°€ ìì²´ OpenAI API í‚¤ë¥¼ ì‚¬ìš©í•˜ë„ë¡ í—ˆìš©í•˜ê³ , st.sidebar ë‚´ë¶€ì˜ st.inputì—ì„œ ì´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
# st.sidebarë¥¼ ì‚¬ìš©í•˜ì—¬ Streamlit app ì˜ ì½”ë“œê³¼ í•¨ê»˜ ê¹ƒí—ˆë¸Œ ë¦¬í¬ì§€í† ë¦¬ì— ë§í¬ë¥¼ ë„£ìŠµë‹ˆë‹¤.

from datetime import datetime
import re
import os
import json
import streamlit as st
from langchain_community.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper
from langchain_community.utilities.wikipedia import WikipediaAPIWrapper
from langchain_community.document_loaders.web_base import WebBaseLoader
import openai as client


# í´ë¼ìš°ë“œí˜ì–´ ê³µì‹ë¬¸ì„œ ì‚¬ì´íŠ¸ë§µ?
# https://developers.cloudflare.com/sitemap.xml


st.set_page_config(
    page_title="AssistantGPT",
    page_icon="ğŸš€",
    layout="wide",
)

st.markdown(
    """
    # ğŸš€ ë¦¬ì„œì¹˜ ë§ˆìŠ¤í„°  ğŸš€ 
    
    ê²€ìƒ‰ì€ ì €ì—ê²Œ ë§¡ê²¨ì£¼ì„¸ìš”! ì—¬ëŸ¬ë¶„ë“¤ì˜ ì‹œê°„ì„ ì•„ê»´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
    (OpenAI Assistant APi ì‚¬ìš©)
 """
)
if "messages" not in st.session_state:
    st.session_state["messages"] = []

if "api_key" not in st.session_state:
    st.session_state["api_key"] = None

if "api_key_check" not in st.session_state:
    st.session_state["api_key_check"] = False

if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "ì„ íƒí•´ì£¼ì„¸ìš”"

if "assistant" not in st.session_state:
    st.session_state["assistant"] = ""

API_KEY_pattern = r"sk-.*"

Model_pattern = r"gpt-*"

openai_models = ["ì„ íƒí•´ì£¼ì„¸ìš”", "gpt-3.5-turbo-0125", "gpt-4-0125-preview"]


class api_key_and_model:
    def __init__(self):
        pass

    def save_api_key(self,api_key):
        st.session_state["api_key"] = api_key
        st.session_state["api_key_check"] = True


    def save_openai_model(self,openai_model):
        st.session_state["openai_model"] = openai_model
        st.session_state["openai_model_check"] = True


class chat_message:
    def __init__(self):
        pass

    def save_message(message, role):
        st.session_state["messages"].append({"message": message, "role": role})


    def send_message(self,message, role, save=True):
        with st.chat_message(role):
            st.markdown(message)

        if save:
            self.save_message(message, role)


    def paint_history(self):
        for message in st.session_state["messages"]:
            self.send_message(
                message["message"],
                message["role"],
                save=False,
            )

def get_run(run_id, thread_id):
    return client.beta.threads.runs.retrieve(
        run_id=run_id,
        thread_id=thread_id,
    )

def send_message(thread_id, content):
    return client.beta.threads.messages.create(
        thread_id=thread_id, role="user", content=content
    )

def get_messages(thread_id):
    messages = client.beta.threads.messages.list(thread_id=thread_id)
    messages = list(messages)
    messages.reverse()
    for message in messages:
        print(f"{message.role}: {message.content[0].text.value}")

def get_tool_outputs(run_id, thread_id):
    run = get_run(run_id, thread_id)
    outputs = []
    for action in run.required_action.submit_tool_outputs.tool_calls:
        action_id = action.id
        function = action.function
        print(f"Calling function: {function.name} with arg {function.arguments}")
        outputs.append(
            {
                "output": functions_map[function.name](json.loads(function.arguments)),
                "tool_call_id": action_id,
            }
        )
    return outputs


def submit_tool_outputs(run_id, thread_id):
    outpus = get_tool_outputs(run_id, thread_id)
    return client.beta.threads.runs.submit_tool_outputs(
        run_id=run_id,
        thread_id=thread_id,
        tool_outputs=outpus,
    )


with st.sidebar:
    api_key = st.text_input(
        "API_KEY ì…ë ¥",
        placeholder="sk-...",
        disabled=st.session_state["api_key"] is not None,
    ).strip()

    if api_key:
        api_key_and_model.save_api_key(api_key)
        st.write("ğŸ˜„API_KEYê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.ğŸ˜„")

    button = st.button("ì €ì¥")

    if button:
        api_key_and_model.save_api_key(api_key)
        if api_key == "":
            st.warning("OPENAI_API_KEYë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")

    st.divider()

    openai_model = st.selectbox(
        "OpneAI Modelì„ ê³¨ë¼ì£¼ì„¸ìš”.",
        options=openai_models,
    )
    if openai_model != "ì„ íƒí•´ì£¼ì„¸ìš”":
        if re.match(Model_pattern, openai_model):
            api_key_and_model.save_openai_model(openai_model)
            st.write("ğŸ˜„ëª¨ë¸ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.ğŸ˜„")

    st.write(
        """


        Made by hary.

        Github
        https://github.com/lips85/normard-langchain/blob/main/pages/06_FinalAssitant.py

        streamlit
        https://nomad-fullstack-langchain-hary.streamlit.app/FinalAssitant

        """
    )

def get_websites_by_wikipedia_search(inputs):
    w = WikipediaAPIWrapper()
    query = inputs["query"]
    return w.run(query)


def get_websites_by_duckduckgo_search(inputs):
    ddg = DuckDuckGoSearchAPIWrapper()
    query = inputs["query"]
    return ddg.run(query)


def get_document_text(inputs):
    url = inputs["url"]
    loader = WebBaseLoader([url])
    docs = loader.load()
    return docs[0].page_content

functions_map = {
    "get_websites_by_wikipedia_search": get_websites_by_wikipedia_search,
    "get_websites_by_duckduckgo_search": get_websites_by_duckduckgo_search,
    "get_document_text": get_document_text,
}

functions = [
    {
        "type": "function",
        "function": {
            "name": "get_websites_by_wikipedia_search",
            "description": "Use this tool to find the websites for the given query.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "The query you will search for. Example query: Research about the XZ backdoor",
                    }
                },
                "required": ["query"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_websites_by_duckduckgo_search",
            "description": "Use this tool to find the websites for the given query.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "The query you will search for. Example query: Research about the XZ backdoor",
                    }
                },
                "required": ["query"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_document_text",
            "description": "Use this tool to load the website for the given url.",
            "parameters": {
                "type": "object",
                "properties": {
                    "url": {
                        "type": "string",
                        "description": "The url you will load. Example url: https://en.wikipedia.org/wiki/Backdoor_(computing)",
                    }
                },
                "required": ["url"],
            },
        },
    },
]

if not api_key:
    st.warning("Please provide an **:blue[OpenAI API Key]** on the sidebar.")

if openai_model == "ì„ íƒí•´ì£¼ì„¸ìš”":
    st.warning("Please write down a **:blue[OpenAI Model Select]** on the sidebar.")

@st.cache_resource(show_spinner="Loading...")
def create_thread(message_content):
    return client.beta.threads.create(
        messages=[
            {
                "role": "user",
                "content": message_content,
            }
        ]
    )

def create_run(thread_id, assistant_id):
    return client.beta.threads.runs.create(
        thread_id=thread_id,
        assistant_id=assistant_id,
    )



if api_key and openai_model != "ì„ íƒí•´ì£¼ì„¸ìš”":
    if st.session_state["assistant"] == "": 
        C_A = st.button("Create Assistant")
        if C_A:
            st.session_state["assistant"] = client.beta.assistants.create(
                name="Super Search Assistant",
                instructions="""
                0. ë‹¹ì‹ ì€ userì˜ Research Assistant ì…ë‹ˆë‹¤.
                1. query ì— ëŒ€í•´ì„œ ê²€ìƒ‰í•˜ê³ 
                2. ê²€ìƒ‰ ê²°ê³¼ ëª©ë¡ì— website url ëª©ë¡ì´ ìˆìœ¼ë©´, ê°ê°ì˜ website ë‚´ìš©ì„ textë¡œ ì¶”ì¶œí•´ì¤˜.  

                """,
                model=st.session_state["openai_model"],
                tools=functions,
            )

            st.write(st.session_state["assistant"])

        message_content = "Research about the XZ backdoor"
        R_A = st.button("Reset Assistant")
        if R_A:
            st.session_state["assistant"] = ""
            st.session_state["messages"] = []





# if (st.session_state["api_key_check"] is True) and (
#     st.session_state["api_key"] is not None
# ):
#     if url:
#         if ".xml" not in url:
#             with st.sidebar:
#                 st.error("Please write down a Sitemap URL.")
#         else:
#             retriever = load_website(url)
#             send_message("I'm ready! Ask away!", "ai", save=False)
#             paint_history()
#             message = st.chat_input("Ask a question to the website.")
#             if message:
#                 if re.match(API_KEY_pattern, st.session_state["api_key"]) and re.match(
#                     Model_pattern, st.session_state["openai_model"]
#                 ):
#                     send_message(message, "human")
#                     try:
#                         chain = (
#                             {
#                                 "docs": retriever,
#                                 "question": RunnablePassthrough(),
#                                 "history": RunnableLambda(load_memory),
#                             }
#                             | RunnableLambda(get_answers)
#                             | RunnableLambda(choose_answer)
#                         )

#                         def invoke_chain(question):
#                             result = chain.invoke(question).content
#                             memory.save_context(
#                                 {"input": question},
#                                 {"output": result},
#                             )
#                             return result

#                         with st.chat_message("ai"):
#                             invoke_chain(message)

#                     except Exception as e:
#                         st.error(f"An error occurred: {e}")
#                         st.warning("OPENAI_API_KEY or ëª¨ë¸ ì„ íƒì„ ë‹¤ì‹œ ì§„í–‰í•´ì£¼ì„¸ìš”.")

#                 else:
#                     message = "OPENAI_API_KEY or ëª¨ë¸ ì„ íƒì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”."
#                     send_message(message, "ai")
#     else:
#         st.session_state["messages"] = []
