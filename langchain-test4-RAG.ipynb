{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, Aaronosn is guilty. The text provides evidence that he committed the crime of thoughtcrime by having unauthorized thoughts about Julia and Winston. This is a serious offense in the totalitarian society they live in, as evidenced by his arrest and interrogation by O'Brien. Additionally, Aaronson's confession to O'Brien further confirms his guilt.<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_community.chat_models.ollama import ChatOllama\n",
    "from langchain.document_loaders.unstructured import UnstructuredFileLoader\n",
    "from langchain_text_splitters.character import CharacterTextSplitter\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain_core.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.storage.file_system import LocalFileStore\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.passthrough import RunnablePassthrough\n",
    "from langchain_core.runnables.base import RunnableLambda\n",
    "from langchain.memory.buffer import ConversationBufferMemory\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "\n",
    "\n",
    "LLM_model = \"ollama\"\n",
    "# LLM_model = \"openai\"\n",
    "\n",
    "file_name = \"document.txt\"\n",
    "\n",
    "if LLM_model == \"openai\":\n",
    "    # 챗 지피티\n",
    "    models = \"gpt-3.5-turbo\"\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0.1,\n",
    "        model=models,\n",
    "        streaming=True,\n",
    "        callbacks=[\n",
    "            StreamingStdOutCallbackHandler(),\n",
    "        ],\n",
    "    )\n",
    "elif LLM_model == \"ollama\":\n",
    "    # 로컬 LLM (ollama)\n",
    "    models = \"openhermes:latest\"\n",
    "    llm = ChatOllama(\n",
    "        temperature=0.1,\n",
    "        model=models,\n",
    "        streaming=True,\n",
    "        callbacks=[\n",
    "            StreamingStdOutCallbackHandler(),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "\n",
    "loader = UnstructuredFileLoader(f\"./files/{file_name}\")\n",
    "\n",
    "cache_dir = LocalFileStore(f\"./.cache/embeddings/{LLM_model}/{models}/{file_name}\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "if LLM_model == \"openai\":\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "elif LLM_model == \"ollama\":\n",
    "    embeddings = OllamaEmbeddings(\n",
    "        model=models,\n",
    "    )\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "ouput_parser = StrOutputParser()\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    llm=llm,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer questions using only the following context. If you don't know the answer just say you don't know, don't make it up:\\n\\n{context}\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"history\": RunnableLambda(load_memory),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | ouput_parser\n",
    ")\n",
    "\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\"question\": question}).content\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result},\n",
    "    )\n",
    "    print(type(result))\n",
    "\n",
    "\n",
    "invoke_chain(\"Is Aaronson guilty?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text provided does not contain any information about a message written on a table. The passage discusses O'Brien and Winston's conversation about power, control, and the nature of reality."
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What message did he write in the table?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia is a character in George Orwell's novel \"1984.\" She is Winston Smith's lover and fellow rebel against the Party. Julia is described as being attractive, with dark hair and eyes, and she works at the Fiction Department of the Ministry of Truth. Throughout the novel, Julia and Winston engage in a secret affair, sharing their rebellious thoughts and dreams of overthrowing the Party. However, their relationship is ultimately used by the Party to break down their individual resistance and force them into conformity."
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Who is Julia?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first question you asked O'Brien in this passage is, \"You have read it?\", referring to The Book (Goldstein's book)."
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What was the first question that i ask you?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
